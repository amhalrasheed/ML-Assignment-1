{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8accd9e2",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d92b0b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d131ca",
   "metadata": {},
   "source": [
    "### Students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea754d80",
   "metadata": {},
   "source": [
    "**Abdullah Baskran  :** 440012378<br>\n",
    "**Abdullah Alrasheed:** 439027348<br>\n",
    "**Sultan Almansour  :** 440016632<br>\n",
    "**Mohammed Alawashiz:** 438020893<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2314cd25",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a25b98",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0692b790",
   "metadata": {},
   "source": [
    "In this program we used the heart dataset to classify if a person has heart disease or not, the classifying is done using a **decision tree**, we described each step of how we built the model and how we overcome the **overfitting** problem using post pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbeea51",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08b006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf063b21",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095735a9",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ec0d9",
   "metadata": {},
   "source": [
    "First, we import the data from the heart dataset that we got and we use a function called \"read_csv()\" from the pandas library to load the data. We give each attribute a name then we show the five-row in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5473316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart.csv\")\n",
    "var_columns = [c for c in df.columns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcfe747",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6fe89",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def927c",
   "metadata": {},
   "source": [
    "After that, we look for any missing data that could be in the dataset, in this case, we go through every column and each value that is in the column then if there is any missing data it will print how many missing values besides the column name that have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2199d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9a137e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ca2488",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429995c1",
   "metadata": {},
   "source": [
    "Now we must split the examples from the target in order to train and test the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1cba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('target', axis='columns')\n",
    "y = df['target']\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840737d8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458d57d8",
   "metadata": {},
   "source": [
    "### Dealing with categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f99d463",
   "metadata": {},
   "source": [
    "after we split the data we face a problem that in some columns, for instance, chest pain column its categorical means it has four types not only two so we have to encode it and we use \"One-hot encode\" that will convert to binary value zero and one but it will create another column, by using \"get_dummies\" function we could able to do it for chest pain column and the rest that have to be encoded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_encoded = pd.get_dummies(x, columns=['cp', 'thal', 'ca', 'slope', 'restecg'])\n",
    "x_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180769c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e2844e",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93a596a",
   "metadata": {},
   "source": [
    "First, we split the data into 70% to train the model and 30% to test the model, then we calculate the accuracy and we got 100% train data accuracy and 80.0% test data accuracy, you can see that the data having overfitting since the training accuracy is a lot greater than test accuracy, then we show the tree that have size 77 which is huge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd3e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.3, random_state=2)\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "\n",
    "tree_clf = tree_clf.fit(x_train, y_train)\n",
    "\n",
    "y_predict_test = tree_clf.predict(x_test)\n",
    "y_predict_train = tree_clf.predict(x_train)\n",
    "\n",
    "print(f'Accuracy of the training sample = {accuracy_score(y_train, y_predict_train)*100}%')\n",
    "print(f'Accuracy of the test sample = {round(accuracy_score(y_test, y_predict_test), 2)*100}%')\n",
    "\n",
    "print(\"Tree size:\", tree_clf.tree_.node_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad21b0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[20, 14])\n",
    "plot_tree(tree_clf, filled=True, class_names=['Not heart disease', 'heart disease'], feature_names=x_encoded.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e1cac8",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277495b",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf78d26",
   "metadata": {},
   "source": [
    "Here is the confusion matrix for train, test data that will help us to find out how many the model failed to classify correctly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdec1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_train = metrics.confusion_matrix(y_predict_train, y_train)\n",
    "cf_test = metrics.confusion_matrix(y_predict_test, y_test)\n",
    "sn.heatmap(cf_train, annot=True, yticklabels=['Not heart disease', 'heart disease'], xticklabels=['Not heart disease', 'heart disease'], cmap='Greens', fmt='g')\n",
    "\n",
    "print(\"confusion Matrix (Train)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"confusion Matrix (Test)\")\n",
    "sn.heatmap(cf_test, annot=True, yticklabels=['Not heart disease', 'heart disease'], xticklabels=['Not heart disease', 'heart disease'], cmap='Greens', fmt='g')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8ef60",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e62589",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286b117",
   "metadata": {},
   "source": [
    "we can calculate precision and recall for train data as well as test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train precision: {metrics.precision_score(y_train, y_predict_train)}')\n",
    "print(f'Train recall: {metrics.recall_score(y_train, y_predict_train)}')\n",
    "print(f'Test precision: {round(metrics.precision_score(y_test, y_predict_test), 2)}')\n",
    "print(f'Test recall: {round(metrics.recall_score(y_test, y_predict_test), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113a43d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5890eb0",
   "metadata": {},
   "source": [
    "### Overfitting issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1399fd",
   "metadata": {},
   "source": [
    "In general, there is a high risk of overfitting the model when using decision trees. Because it becomes increasingly complex as the depth and number of splits increase. As a result, the model's variance increases. Although this reduces training error, prediction on new data points is relatively poor. As a result, the pruning procedure comes to the rescue.\n",
    "\n",
    "Decision Tree pruning ensures that a full tree is pruned in order to reduce the model's complexity and variance. It makes the decision tree versatile enough to adapt to any new data fed to it, thereby resolving the overfitting problem. It reduces the size of the decision tree, which may slightly increase training error but significantly reduces testing error. As a result, it has become more adaptable.\n",
    "\n",
    "**There are two types of pruning: (pre-pruning) and (post-pruning)**\n",
    "\n",
    "**In our model we will use (post-pruning)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282415d3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e42a4",
   "metadata": {},
   "source": [
    "# Post pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1242dd8c",
   "metadata": {},
   "source": [
    "post pruning is applied after building the tree, the algorithm we are using is **cost_complexity_pruning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfbedb4",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f6aad",
   "metadata": {},
   "source": [
    "first, we need to calculate **alpha** in order to calculate the accuracy score for each one, in the code below we got all available alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939acb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = tree_clf.cost_complexity_pruning_path(x_train, y_train)\n",
    "alphas = path['ccp_alphas']\n",
    "\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d39b7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde7e40",
   "metadata": {},
   "source": [
    "In this part, we calculated train accuracy, test accuracy, tree size, tree depth, and the mean and standard deviation of alpha for every value of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = []\n",
    "acc_test = []\n",
    "tree_size = []\n",
    "tree_depth = []\n",
    "alpha_values = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    temp_tree = DecisionTreeClassifier(ccp_alpha=alpha, criterion=\"entropy\", random_state=0)\n",
    "    temp_tree.fit(x_train, y_train)\n",
    "\n",
    "    y_predect_train, y_predect_test = temp_tree.predict(x_train), temp_tree.predict(x_test)\n",
    "    \n",
    "    scores = cross_val_score(temp_tree, x_train, y_train, cv=5)\n",
    "    \n",
    "    alpha_values.append([alpha, np.mean(scores), np.std(scores)])\n",
    "    tree_depth.append(temp_tree.get_depth())\n",
    "    tree_size.append(temp_tree.tree_.node_count)\n",
    "    acc_train.append(accuracy_score(y_train, y_predect_train))\n",
    "    acc_test.append(accuracy_score(y_test, y_predect_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(tree_size, acc_train, label='train_accuracy')\n",
    "plt.plot(tree_size, acc_test, label='test_accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel(\"size(tree)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title('Accuracy vs tree(size) (Figure 1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b5d8b",
   "metadata": {},
   "source": [
    "Figure (**1**) shows that as tree size increase the accuracy of training data increases while test accuracy decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a99c939",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c30e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(alphas, tree_depth)\n",
    "plt.xticks(ticks=np.arange(0.00, 0.26, 0.005), rotation=60)\n",
    "plt.xlabel(\"alphas\")\n",
    "plt.ylabel(\"tree depth\")\n",
    "plt.title('depth vs alphas (Figure 2)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9835f",
   "metadata": {},
   "source": [
    "Figure (**2**) shows that the relationship between alpha and tree depth is inversely proportional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1a957",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d67d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.scatter(alphas, acc_train)\n",
    "plt.scatter(alphas, acc_test)\n",
    "plt.plot(alphas, acc_train, label='train_accuracy', drawstyle=\"steps-post\")\n",
    "plt.plot(alphas, acc_test, label='test_accuracy', drawstyle=\"steps-post\")\n",
    "plt.xlabel(\"alphas\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xticks(ticks=np.arange(0.00, 0.2, 0.005), rotation=60)\n",
    "plt.yticks(ticks=np.arange(0.00, 1.00, 0.05))\n",
    "plt.legend()\n",
    "plt.title('Accuracy vs alpha (Figure 3)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85798597",
   "metadata": {},
   "source": [
    "Figure (**3**) shows the training and test accuracy for each alpha point, we can see that between 0.02 and 0.03 we got the highest accuracy result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd66ebc2",
   "metadata": {},
   "source": [
    "**From fig(2) and fig(3), we concluded that a high increase in alpha gives smaller tree (good) and low accuracy (bad), so we need to increase it to the point that reduces the tree size and increase the accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd3600",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e368ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_result = pd.DataFrame(alpha_values, columns=['alpha', 'mean_accuracy', 'std'])\n",
    "alpha_result.plot(x='alpha', y='mean_accuracy', yerr='std', marker='o', linestyle='--', figsize=(14, 7), xticks=np.arange(0, 0.2, 0.005), grid=True, rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b69f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_result[(alpha_result['alpha'] > 0.02) & (alpha_result['alpha'] < 0.03)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f0be39",
   "metadata": {},
   "source": [
    "From the table above we can see that **ccp_alpha = 0.026781** will yield the best accuracy for our tree model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e10ac",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324b60c",
   "metadata": {},
   "source": [
    "### Building the decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac854f",
   "metadata": {},
   "source": [
    "As you can see below we used the **ccp_alpha** value we got from our previous calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=0, criterion='entropy', ccp_alpha=0.026781)\n",
    "tree_clf = tree_clf.fit(x_train, y_train)\n",
    "\n",
    "y_predict_test1 = tree_clf.predict(x_test)\n",
    "y_predict_train1 = tree_clf.predict(x_train)\n",
    "\n",
    "print(f'Accuracy of the training sample = {round(accuracy_score(y_train, y_predict_train1), 3)*100}%')\n",
    "print(f'Accuracy of the test sample = {round(accuracy_score(y_test, y_predict_test1), 3)*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ba122",
   "metadata": {},
   "source": [
    "**You can clearly see Above the difference in accuracy between the previous and the new model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb15c8d",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96d05f6",
   "metadata": {},
   "source": [
    "For tree size we got 15 nodes vs 77 in the old tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15, 7.5])\n",
    "plot_tree(tree_clf, filled=True, class_names=['Not heart disease', 'heart disease'], feature_names=x_encoded.columns)\n",
    "\n",
    "print(\"Tree size:\", tree_clf.tree_.node_count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_train = metrics.confusion_matrix(y_predict_train1, y_train)\n",
    "cf_test = metrics.confusion_matrix(y_predict_test1, y_test)\n",
    "sn.heatmap(cf_train, annot=True, yticklabels=['Not heart disease', 'heart disease'], xticklabels=['Not heart disease', 'heart disease'], cmap='Greens', fmt='g')\n",
    "\n",
    "print(\"confusion Matrix (Train)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"confusion Matrix (Test)\")\n",
    "sn.heatmap(cf_test, annot=True, yticklabels=['Not heart disease', 'heart disease'], xticklabels=['Not heart disease', 'heart disease'], cmap='Greens', fmt='g')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train precision: {round(metrics.precision_score(y_train, y_predict_train1), 2)}')\n",
    "print(f'Train recall: {round(metrics.recall_score(y_train, y_predict_train1), 2)}')\n",
    "print(f'Test precision: {round(metrics.precision_score(y_test, y_predict_test1), 2)}')\n",
    "print(f'Test recall: {round(metrics.recall_score(y_test, y_predict_test1), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d98615",
   "metadata": {},
   "source": [
    "**From the confusion matrices and the results above we think we solved the overfitting problem**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
